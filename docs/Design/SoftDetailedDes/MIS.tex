\documentclass[12pt, titlepage]{article}

\usepackage{amsmath, mathtools}

% \usepackage[round]{natbib}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{xr}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{xfrac}
\usepackage{tabularx}
\usepackage{float}
\usepackage{siunitx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[section]{placeins}
\usepackage{caption}
\usepackage{fullpage}

\hypersetup{
bookmarks=true,     % show bookmarks bar?
colorlinks=true,       % false: boxed links; true: colored links
linkcolor=red,          % color of internal links (change box color with linkbordercolor)
citecolor=blue,      % color of links to bibliography
filecolor=magenta,  % color of file links
urlcolor=cyan          % color of external links
}

\usepackage{array}

\externaldocument{../../SRS/SRS}

\input{../../Comments}
\input{../../Common}

\begin{document}

\title{Module Interface Specification for \progname{}}

\author{\authname}

\date{\today}

\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Name} & {\bf Notes}\\
\midrule
January 17th, 2025 & All & Initial Draft\\
March 24th, 2025 & Mya Hussain & Removed Pythonic Syntax Mentions\\
March 24th, 2025 & Mya Hussain & Added Some References to Local Functions\\
March 24th, 2025 & Mya Hussain & Modified Wrong Environment Variables\\
\bottomrule
\end{tabularx}

~\newpage

\section{Symbols, Abbreviations and Acronyms}

See \href{https://github.com/ssm-lab/capstone--source-code-optimizer/blob/main/docs/SRS/SRS.pdf}{SRS} Documentation.

\wss{Also add any additional symbols, abbreviations or acronyms}

\newpage

\tableofcontents

\newpage

\pagenumbering{arabic}

\section{Introduction}

The following document details the Module Interface Specifications (MIS) for the Source Code Optimizer project. The Source Code Optimizer is a software tool designed to analyze, refactor, and optimize Python source code to improve energy efficiency, maintainability, and performance. This tool incorporates a combination of static code analysis using Pylint, abstract syntax tree (AST) parsing, and custom refactoring techniques to detect and address various code smells in Python programs.

The application allows developers to identify inefficient coding patterns, refactor them into optimized alternatives, and validate the results through built-in testing mechanisms. Key features include support for custom smell detection, energy profiling, and modular refactorers tailored to specific code smells, such as long method chains or inefficient list comprehensions. By automating parts of the optimization process, the Source Code Optimizer helps developers have the option of choosing to reduce emissions and produce more efficient software.

Complementary documents include the System Requirement Specifications (SRS) and Module Guide (MG). The full documentation and implementation can be found at: \url{https://github.com/ssm-lab/capstone--source-code-optimizer}

\section{Notation}

The following table summarizes the primitive data types used by \progname. 

\begin{table}
  \centering
  \renewcommand{\arraystretch}{1.2}
  \noindent 
  \begin{tabular}{l l p{7.5cm}} 
    \toprule 
    \textbf{Data Type} & \textbf{Notation} & \textbf{Description}\\ 
    \midrule
    optional & ? & denotes a variable as optional\\
    any type & Any & any data type is acceptable\\
    character & char & a single symbol or digit\\
    String & str & a sequence of characters\\
    integer & $\mathbb{Z}$ & a number without a fractional component in (-$\infty$, $\infty$) \\
    natural number & $\mathbb{N}$ & a number without a fractional component in [1, $\infty$) \\
    real & $\mathbb{R}$ & any number in (-$\infty$, $\infty$)\\
    boolean & $\mathbb{B}$ & True or False\\
    code smell & Smell & a collection of data representing a code smell\\
    path & Path & Data object representing a path in a filesystem\\
    list & list[T] & an ordered collection of objects of type T\\
    set & set[T] & an unordered collection of \textit{unique} objects of type T\\
    dictionary & dict[key] = value & data structure containing multiple key-value pairs\\
    AST Node & AST & AST node representing any AST node\\
    AST Constant & Constant & AST node representing a constant\\
    AST Function Definition & FuncDef & AST node representing a function definition\\
    AST Module & Module & AST node representing a Module\\
    AST Class Definition & ClassDef & ast node representing a class definition\\
    AST Call & Call & ast node representing a function call\\
    AST Lambda & Lambda & ast node representing a lambda function\\
    AST List Comprehension & ListComp & ast node representing a list comprehension\\
    AST Generator Expression & GenExp & ast node representing a generator expression\\
    current instance & self & a reference to the current instance of a module\\
    \bottomrule
  \end{tabular}
  \label{tab:mis-notation}
  \caption{MIS Notation}
\end{table}

\noindent
The specification of \progname \ uses some derived data types: sequences, strings, and
tuples. Sequences are lists filled with elements of the same data type. Strings
are sequences of characters. Tuples contain a list of values, potentially of
different types. In addition, \progname \ uses functions, which
are defined by the data types of their inputs and outputs. Local functions are
described by giving their type signature followed by their specification.

\section{Module Decomposition}

The following table is taken directly from the Module Guide document for this project.

\begin{table}[h!]
  \centering
  \begin{tabular}{p{0.3\textwidth} p{0.6\textwidth}}
    \toprule
    \textbf{Level 1} & \textbf{Level 2}\\
    \midrule
    
    {Hardware-Hiding Module} & None \\
    \midrule
    
    \multirow{7}{0.3\textwidth}{Behaviour-Hiding Module} & Smell Module\\
    & BaseRefactorer Module\\
    & MakeStaticRefactorer Module\\
    & UseListAccumulationRefactorer Module\\
    & UseAGeneratorRefactorer Module\\
    & CacheRepeatedCallsRefactorer Module\\
    & LongElementChainRefactorer Module\\
    & LongParameterListRefactorer Module\\
    & LongMessageChainRefactorer Module\\
    & LongLambdaFunctionRefactorer Module\\ 
    & PluginInitiator Module\\
    & BackendCommunicator Module\\ 
    & SmellDetector Module\\
    & FileHighlighter Module\\
    & HoverManager Module\\
    \midrule
    
    
    \multirow{3}{0.3\textwidth}{Software Decision Module} & Measurements Module\\
    & PylintAnalyzer Module\\
    & Testing Functionality Module\\
    & SmellRefactorer Module\\
    & RefactorManager Module\\
    \bottomrule
  \end{tabular}
  \caption{Module Hierarchy}
  \label{TblMH}
\end{table}

~\newpage

\section{MIS of Smell Data Type} \label{mis:smell}
\texttt{Smell}

\subsection{Module}
Contains data related to a code smell.

\subsection{Uses}
None

\subsection{Syntax}
\noindent
\textbf{Exported Constants}: None

\noindent
\textbf{Exported Access Programs}: None

\subsection{Semantics}

\subsubsection{State Variables}
\begin{itemize}
  \item \texttt{absolutePath: str}: Absolute path to the source file containing the smell.
  \item \texttt{column: int}: Starting column in the source file where the smell is detected.
  \item \texttt{confidence: str}: Confidence level for the smell detection.
  \item \texttt{endColumn?: int}: Ending column for the smell location, if applicable.
  \item \texttt{endLine?: int}: Ending line number for the smell location, if applicable.
  \item \texttt{occurences: dict}: Contains positional data related to where the smell is located in a code file.
  \item \texttt{message: str}: Descriptive message explaining the smell.
  \item \texttt{messageId: str}: Unique identifier for the specific message or warning.
  \item \texttt{module: str}: Module or component name containing the smell.
  \item \texttt{obj: str}: Specific object associated with the smell.
  \item \texttt{path: str}: Relative path to the source file from the project root.
  \item \texttt{symbol: str}: Symbol or code construct involved in the smell.
  \item \texttt{type: str}: Type or category of the smell.
\end{itemize}

\subsubsection{Environment Variables}
None

\subsubsection{Assumptions}
\begin{itemize}
  \item All values provided to the fields of \texttt{Smell} conform to the expected data types and constraints.
\end{itemize}

\subsubsection{Access Routine Semantics}

\paragraph{\texttt{Smell()}}
\begin{itemize}
  \item \textbf{transition}: Creates a dictionary-like structure with the defined attributes representing a code smell.
  \item \textbf{output}: Returns a \texttt{Smell} instance.
\end{itemize}

\subsubsection{Local Functions}
None.
  

\newpage

\section{MIS of Base Refactorer} \label{mis:baseR}

\texttt{BaseRefactorer}

\subsection{Module}

The interface that all refactorers of this system will inherit from.

\subsection{Uses}

None

\subsection{Syntax}
\noindent
\textbf{Exported Constants}: None

\noindent
\textbf{Exported Access Programs}:

\begin{tabularx}{\linewidth}{|l|>{\raggedright\arraybackslash}X|l|l|}
  \hline
  \textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\\hline
  \texttt{BaseRefactorer} & \texttt{output\_dir: Path} & \texttt{self} & None \\\hline
  \texttt{refactor} & \texttt{file\_path: Path, pylint\_smell: dict, initial\_emissions: $\mathbb{R}$} & None & None \\
  \hline
\end{tabularx}

\subsection{Semantics}

\subsubsection{State Variables}
\begin{itemize}
  \item \texttt{temp\_dir: Path}: Directory path for storing refactored files.
\end{itemize}

\subsubsection{Environment Variables}
None

\subsubsection{Assumptions}
\begin{itemize}
  \item \texttt{output\_dir} exists or can be created, and write permissions are available.
\end{itemize}

\subsubsection{Access Routine Semantics}

\paragraph{\texttt{BaseRefactorer(self, output\_dir: Path)}}
\begin{itemize}
  \item \textbf{transition}: Initializes the \texttt{temp\_dir} variable within \texttt{output\_dir}.
  \item \textbf{output}: \texttt{self}
  \item \textbf{exception:} None.
\end{itemize}

\paragraph{\texttt{refactor(self, file\_path: Path, pylint\_smell: dict, initial\_emissions: $\mathbb{R}$)}}
\begin{itemize}
  \item \textbf{transition}: Abstract method. No transition defined.
  \item \textbf{output}: None.
  \item \textbf{exception:} None.
\end{itemize}

\subsubsection{Local Functions}
None.

\newpage


\section{MIS of Long Message Chain Refactorer} \label{mis:LMC}

\texttt{LongMessageChainRefactorer}

\subsection{Module}

LongMessageChainRefactorer is a module that identifies and refactors long message chains in Python code to improve readability, maintainability, and performance. It specifically handles long chains by breaking them into separate statements, ensuring proper refactoring while maintaining the original functionality.

\subsection{Uses}

\begin{itemize}
  \item Uses \texttt{Smell} interface for data access
  \item Inherits from \texttt{BaseRefactorer}
\end{itemize}

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabularx}{\linewidth}{|l|>{\raggedright\arraybackslash}X|p{1in}|p{1in}|}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
\texttt{LongMessageChainRefactorer} & \texttt{output\_dir: Path} & \texttt{self} & None \\
\hline
\texttt{refactor} & \texttt{file\_path: Path, pylint\_smell: Smell, initial\_emissions: $\mathbb{R}$} & None & \texttt{TypeError}, \texttt{IOError} \\
\hline
\end{tabularx}
\end{center}


\subsection{Semantics}

\subsubsection{State Variables}

\begin{itemize}
  \item \textbf{temp\_dir}: Temporary directory for intermediate refactored files.
\end{itemize}

\subsubsection{Environment Variables}
None


\subsubsection{Assumptions}

\begin{itemize}
  \item Input files are valid Python scripts.
  \item Smells identified by \textbf{pylint\_smell} include valid line numbers.
  \item Refactored code must pass the provided test suite.
\end{itemize}
\subsubsection{Access Routine Semantics}

\paragraph{\texttt{LongMessageChainRefactorer(output\_dir: Path)}}
\begin{itemize}
\item \textbf{Transition}: Initializes the refactorer with the specified output directory.
\item \textbf{Output}: \texttt{self}.
\item \textbf{Exception}: None.
\end{itemize}

\paragraph{\texttt{refactor(file\_path: Path, pylint\_smell: Smell, initial\_emissions: $\mathbb{R}$)}}
\begin{itemize}
  \item \textbf{Transition}:
    \begin{itemize}
    \item Reads the file at \texttt{file\_path}.
    \item Identifies the line with a long message chain and uses local function \texttt{remove\_unmatched\_brackets(input\_string: str)}.
    \item Refactors the chain by breaking it into separate statements.
    \item Writes the refactored code to a temporary file.
    \item Evaluates the refactored codeâ€™s energy efficiency and functionality.
    \end{itemize}
  \item \textbf{Output}: None. Refactored file is saved if improvements are validated.
  \item \textbf{Exception}: Raises \texttt{IOError} if input file cannot be read. Raises \texttt{TypeError} if source file cannot be parsed into an AST.
\end{itemize}

\subsubsection{Local Functions}
\paragraph{\texttt{remove\_unmatched\_brackets(input\_string: str)}}
\begin{itemize}
\item \textbf{Transition}: Removes unmatched parentheses from the input string.
\item \textbf{Output}: Returns the string with unmatched parentheses removed.
\item \textbf{Exception}: None.
\end{itemize}

~\newpage

\section{MIS of Long Lambda Function Refactorer} \label{mis:LLF}

\texttt{LongLambdaFunctionRefactorer}

\subsection{Module}
LongLambdaFunctionRefactorer is a module that refactors 
long lambda functions in Python code by converting them into normal functions. 
This improves code readability, maintainability, and performance, while reducing potential energy consumption.

\subsection{Uses}
\begin{itemize}
  \item Uses \texttt{Smell} interface for data access
  \item Inherits from \texttt{BaseRefactorer}
\end{itemize}

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabularx}{\linewidth}{|l|>{\raggedright\arraybackslash}X|p{1in}|p{1in}|}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
\texttt{LongLambdaFunctionRefactorer} & \texttt{output\_dir: Path} & \texttt{self} & None \\
\hline
\texttt{refactor} & \texttt{file\_path: Path, pylint\_smell: Smell, initial\_emissions: $\mathbb{R}$} & None & \texttt{TypeError}, \texttt{IOError} \\
\hline
\end{tabularx}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

\begin{itemize}
  \item \textbf{temp\_dir}: Temporary directory for intermediate refactored files.
\end{itemize}

\subsubsection{Environment Variables}
None


\subsubsection{Assumptions}

\begin{itemize}
  \item Input files are valid Python scripts.
  \item Smells identified by \textbf{pylint\_smell} include valid line numbers.
  \item Refactored code must pass the provided test suite.
\end{itemize}

\subsubsection{Access Routine Semantics}

\paragraph{\texttt{LongLambdaFunctionRefactorer(output\_dir: Path)}}
\begin{itemize}
\item \textbf{Transition}: Initializes the refactorer with the specified output directory.
\item \textbf{Output}: \texttt{self}.
\item \textbf{Exception}: None.
\end{itemize}

\paragraph{\texttt{refactor(file\_path: Path, pylint\_smell: Smell, initial\_emissions: $\mathbb{R}$)}}
\begin{itemize}
  \item \textbf{Transition}:
    \begin{itemize}
    \item Reads the file at \texttt{file\_path}.
    \item Identifies the line with a long lambda function using local function \texttt{truncate\_at\_top\_level\_comma(body: str)}.
    \item Refactors the lambda into a normal function.
    \item Writes the refactored code to a temporary file.
    \end{itemize}
  \item \textbf{Output}: None. Refactored file is saved if improvements are validated.
  \item \textbf{Exception}: Raises \texttt{IOError} if input file cannot be read. Raises \texttt{TypeError} if source file cannot be parsed into an AST.
\end{itemize}

\subsubsection{Local Functions}
\paragraph{\texttt{truncate\_at\_top\_level\_comma(body: str)}}
\begin{itemize}
\item \textbf{Transition}: Truncates the lambda body at the first top-level comma, ignoring commas within nested parentheses, brackets, or braces.
\item \textbf{Output}: Returns the truncated lambda body as a string.
\item \textbf{Exception}: None.
\end{itemize}

~\newpage

\section{MIS of Long Parameter List Refactorer} \label{Module} 

\texttt{LongParameterListRefactorer}

\subsection{Module}

LongParameterListRefactorer is a module that identifies and refactors functions or methods with long parameter lists(detected beyond configured threshold) in Python code. The refactoring aims to improve code readability, maintainability, and energy efficiency by encapsulating related parameters into objects and removing unused ones.

\subsection{Uses}

\begin{itemize}
  \item Uses \texttt{Smell} interface for data access
  \item Inherits from \texttt{BaseRefactorer}
  \item Inherits from Python's \texttt{ast} module's \texttt{NodeTransformer}
\end{itemize}

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabularx}{\linewidth}{|l|>{\raggedright\arraybackslash}X|l|l|}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
\texttt{LongParameterListRefactorer} & \texttt{output\_dir: Path} & \texttt{self} & None \\
\hline
\texttt{refactor} & \texttt{file\_path: Path, pylint\_smell: Smell, initial\_emissions: $\mathbb{R}$} & None & \texttt{TypeError}, \texttt{IOError} \\
\hline
\end{tabularx}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}
None

\subsubsection{Assumptions}

\begin{itemize}
  \item Input files are valid Python scripts.
  \item Smells identified by \texttt{pylint\_smell} include valid line numbers.
  \item Refactored code must pass the provided test suite.
\end{itemize}

\subsubsection{Access Routine Semantics}

\paragraph{\texttt{LongParameterListRefactorer(output\_dir: Path)}}
\begin{itemize}
\item \textbf{Transition}: Initializes the refactorer with the specified output directory.
\item \textbf{Output}: \texttt{self}.
\item \textbf{Exception}: None.
\end{itemize}

\paragraph{\texttt{refactor(file\_path: Path, pylint\_smell: Smell, initial\_emissions: $\mathbb{R}$)}}
\begin{itemize}
  \item \textbf{Transition}:
  \begin{enumerate}
  \item Reads the file at \texttt{file\_path} and locates the target function using \texttt{pylint\_smell}.
  \item Analyzes function body to group parameters into used and ununsed parameters using \texttt{get\_used\_parameters()} to remove unused parameters. Updates the function signature and references in the code accordingly.
  \item If number of used parameters also exceeds the maximum configured limit, encapsulates related parameters into classes using \texttt{classify\_parameters()} and \texttt{create\_parameter\_object\_class()}. Updates the function signature using local function \texttt{update\_function\_signature()} and references in the code  using \texttt{update\_function\_calls()} and \texttt{update\_parameter\_usages()}.
  \item Writes the refactored code to a temporary file.
  \end{enumerate}
  \item \textbf{Output}: None. Refactored file is saved if improvements are validated. 
  \item \textbf{Exception}: Raises \texttt{IOError} if input file cannot be read. Raises \texttt{TypeError} if source file cannot be parsed into an AST.
  \end{itemize}

\subsubsection{Local Functions}

\begin{enumerate}
  \item \texttt{get\_used\_parameters(function\_node: ast.FunctionDef, params: list[str]) -> list[str]}: 
  \begin{itemize}
    \item \textbf{transition}: Identifies parameters used within the function body.
    \item \textbf{output}: List of names of parameters that are actually used in the function.
    \item \textbf{exception}: None
  \end{itemize}
  \item \texttt{get\_parameters\_with\_default\_value(params: list[ast.Param]) -> key-value pairs}: 
  \begin{itemize}
    \item \textbf{transition}: Maps parameter names to their default values .
    \item \textbf{output}: Key-value pairs mapping parameter names to their default values.
    \item \textbf{exception}: None
  \end{itemize}
  \item \texttt{classify\_parameters(params: list[str]) -> key-value pairs}: 
  \begin{itemize}
    \item \textbf{transition}: Classifies parameters into \texttt{data} and \texttt{config} groups based on naming conventions.
    \item \textbf{output}: Key-value pairs with keys "data\_params" and "config\_params" mapping to lists of parameter names.
    \item \textbf{exception}: None
  \end{itemize}
  \item \texttt{create\_parameter\_object\_class(param\_names: list[str], default\_value\_params: key-value pairs, class\_name: str) -> ast.ClassDef}: 
  \begin{itemize}
    \item \textbf{transition}: Creates an AST class definition for encapsulating related parameters.
    \item \textbf{output}: AST ClassDef node representing the parameter object class.
    \item \textbf{exception}: None
  \end{itemize}
  \item \texttt{update\_function\_signature(function\_node: ast.FunctionDef, classified\_params: key-value pairs) -> ast.FunctionDef}:
  \begin{itemize}
    \item \textbf{transition}: Updates function signatures to use encapsulated parameter objects.
    \item \textbf{output}: Updated AST FunctionDef node with new parameter structure.
    \item \textbf{exception}: None
  \end{itemize}
  \item \texttt{update\_parameter\_usages(function\_node: ast.FunctionDef, classified\_params: key-value pairs) -> ast.FunctionDef}: 
  \begin{itemize}
    \item \textbf{transition}: Updates parameter references in function body to use encapsulated object attributes.
    \item \textbf{output}: Updated AST FunctionDef node with transformed parameter usages.
    \item \textbf{exception}: None
  \end{itemize}
  \item \texttt{update\_function\_calls(tree: ast.Module, function\_node: ast.FunctionDef, used\_params: list[str], classified\_params: key-value pairs, classified\_param\_names: tuple[str, str], enclosing\_class\_name: str) -> ast.Module}: 
  \begin{itemize}
    \item \textbf{transition}: Updates all calls to the refactored function to use new parameter structure.
    \item \textbf{output}: Updated AST Module node with transformed function calls.
    \item \textbf{exception}: None
  \end{itemize}
  \end{enumerate}

  \section{MIS of Use List Accumulation Refactorer} \label{mis:ListAccum}

  \texttt{UseListAccumulationRefactorer}
  
  \subsection{Module}
  
  The \texttt{UseListAccumulationRefactorer} module identifies and refactors 
  string concatenations in loops in Python code to improve the performance and energy efficiency of the software. It specifically handles these concatenations by, instead, adding the string for each iteration to a list that is then converted to a string, ensuring proper refactoring while maintaining the original functionality.
  
  \subsection{Uses}
  \begin{itemize}
  \item Uses \texttt{Smell} interface for data access
  \item Inherits from \texttt{BaseRefactorer}
  \item Uses \texttt{astroid} library for AST manipulation
  \end{itemize}
  
  \subsection{Syntax}
  \noindent
  \textbf{Exported Constants}: None
  
  \noindent
  \textbf{Exported Access Programs}:
  
  \begin{tabularx}{\linewidth}{|
      l|
      >{\raggedright\arraybackslash}X|
      l|
      l|}
    \hline
    \textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
    \hline
    \texttt{UseListAccumulationRefactorer} & \texttt{output\_dir: Path} & \texttt{self} & None \\
    \hline
    \texttt{refactor} & \texttt{file\_path: Path, pylint\_smell: Smell, initial\_emissions: Real} & None & \texttt{TypeError}, \texttt{IOError} \\
    \hline
  \end{tabularx}
  
  \subsection{Semantics}
  
  \subsubsection{State Variables}
  \begin{itemize}
  \item \texttt{target\_lines: list[int]}: Line numbers requiring refactoring
  \item \texttt{assign\_var: str}: Target concatenation variable name
  \item \texttt{target\_node: NodeNG}: AST node of concatenation target
  \item \texttt{last\_assign\_node: Assign|AugAssign}: Last variable assignment before loop
  \item \texttt{concat\_nodes: list[Assign|AugAssign]}: Detected concatenation nodes
  \item \texttt{reassignments: list[Assign]}: Variable reassignments in loop scope
  \item \texttt{outer\_loop: For|While}: Outermost loop containing concatenations
  \end{itemize}
  
  \subsubsection{Environment Variables}
  None
  
  \subsubsection{Assumptions}
  \begin{itemize}
  \item Input files contain valid Python syntax
  \item Smell detection provides valid line numbers and variable names
  \end{itemize}
  
  \subsubsection{Access Routine Semantics}
  
  \paragraph{\texttt{UseListAccumulationRefactorer(output\_dir: Path)}}
  \begin{itemize}
  \item \textbf{Transition}: Initializes refactorer with output directory
  \item \textbf{Output}: \texttt{self}
  \item \textbf{Exception}: None
  \end{itemize}
  
  \paragraph{\texttt{refactor(file\_path: Path, pylint\_smell: Smell, initial\_emissions: 
  R
  R)}}
  \begin{itemize}
  \item \textbf{Transition}:
  \begin{itemize}
  \item Parses code using \texttt{visit} pattern for AST traversal
  \item Identifies concatenations with \texttt{find\_reassignments}
  \item Determines scope via \texttt{find\_scope} and \texttt{find\_last\_assignment}
  \item Generates temp names with \texttt{generate\_temp\_list\_name}
  \item Modifies code using \texttt{add\_node\_to\_body}
  \item Validates transformations before writing to refactored file
  \end{itemize}
  \item \textbf{Output}: None
  \item \textbf{Exception}:
  \begin{itemize}
  \item \texttt{IOError}: File read/write failures
  \item \texttt{TypeError}: AST parsing errors
  \end{itemize}
  \end{itemize}
  
  \subsubsection{Local Functions}
  
  \paragraph{\texttt{visit(node: NodeNG)}}
  \begin{itemize}
  \item \textbf{Transition}: Collects concatenation nodes and loop structures
  \item \textbf{Output}: None
  \item \textbf{Exception}: None
  \end{itemize}
  
  \paragraph{\texttt{find\_reassignments()}}
  \begin{itemize}
  \item \textbf{Transition}: Finds variable reassignments in loop scope
  \item \textbf{Output}: None
  \item \textbf{Exception}: None
  \end{itemize}
  
  \paragraph{\texttt{find\_last\_assignment(scope: NodeNG)}}
  \begin{itemize}
  \item \textbf{Transition}: Locates final variable assignment before loop
  \item \textbf{Output}: None
  \item \textbf{Exception}: Raises \texttt{TypeError} for invalid scope
  \end{itemize}
  
  \paragraph{\texttt{find\_scope()}}
  \begin{itemize}
  \item \textbf{Transition}: Determines insertion point for list initialization
  \item \textbf{Output}: None
  \item \textbf{Exception}: Requires \texttt{concat\_nodes} to be populated
  \end{itemize}
  
  \paragraph{\texttt{generate\_temp\_list\_name()}}
  \begin{itemize}
  \item \textbf{Transition}: Creates unique list name for complex targets
  \item \textbf{Output}: Returns generated name string
  \item \textbf{Exception}: Raises \texttt{TypeError} for unsupported nodes
  \end{itemize}
  
  \paragraph{\texttt{add\_node\_to\_body(code\_file: str, nodes\_to\_change: list[tuple])}}
  \begin{itemize}
  \item \textbf{Transition}:
  \begin{itemize}
  \item Replaces concatenations with list operations
  \item Adds join() call and list initialization
  \end{itemize}
  \item \textbf{Output}: Returns modified source code
  \item \textbf{Exception}: Requires valid node references
  \end{itemize}

  
\newpage

\section{MIS of Make Method Static Refactorer} \label{mis:MakeStatic}

\texttt{MakeStaticRefactorer}

\subsection{Module}

The \texttt{MakeStaticRefactorer} module identifies and refactors 
class methods that don't make use of their instance attributes to improve the readability, performance and energy efficiency of the software. It specifically handles these methods by turning them into static functions and ensuring any calls to this method use the proper calling syntax. This ensures proper refactoring while maintaining the original functionality.

\subsection{Uses}
\begin{itemize}
\item Uses \texttt{Smell} interface for data access
\item Inherits from \texttt{MultiFileRefactorer}
\item Uses \texttt{libcst} and \texttt{astroid} for AST manipulation
\end{itemize}

\subsection{Syntax}
\noindent
\textbf{Exported Constants}: None \\

\noindent
\textbf{Exported Access Programs}: \\
\begin{tabularx}{\linewidth}{|l|>{\raggedright\arraybackslash}X|l|l|}
  \hline
  \textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
  \hline
  \texttt{MakeStaticRefactorer} & \texttt{output\_dir: Path} & \texttt{self} & None \\
  \hline
  \texttt{refactor} & \texttt{file\_path: Path, pylint\_smell: Smell, initial\_emissions: $\mathbb{R}$} & None & \texttt{TypeError}, \texttt{IOError} \\
  \hline
\end{tabularx}

\subsection{Semantics}

\subsubsection{State Variables}
\begin{itemize}
\item \texttt{target\_line: int}: Line number of method to refactor
\item \texttt{mim\_method\_class: str}: Containing class name
\item \texttt{mim\_method: str}: Target method name
\item \texttt{valid\_classes: set[str]}: Valid class/subclass names
\item \texttt{transformer: CallTransformer}: CST modification tool
\end{itemize}

\subsubsection{Environment Variables}
None

\subsubsection{Assumptions}
\begin{itemize}
\item Input files contain valid Python syntax
\item Smell detection provides valid method locations
\item Class hierarchies remain consistent across files
\end{itemize}

\subsubsection{Access Routine Semantics}

\paragraph{\texttt{MakeStaticRefactorer()}}
\begin{itemize}
\item \textbf{Transition}: Initializes refactorer with empty state
\item \textbf{Output}: \texttt{self}
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{refactor(file\_path: Path, smell: MIMSmell, ...)}}
\begin{itemize}
\item \textbf{Transition}:
\begin{itemize}
\item Identifies target method using \texttt{\_find\_subclasses}
\item Processes calls with \texttt{find\_valid\_method\_calls}
\item Modifies method definition via \texttt{leave\_FunctionDef}
\item Transforms calls using \texttt{CallTransformer}
\item Validates with \texttt{check\_for\_annotations} and \texttt{check\_for\_initializations}
\item Writes the refactored code to a temporary file.
\end{itemize}
\item \textbf{Output}: None
\item \textbf{Exception}:
\begin{itemize}
\item \texttt{IOError}: File access failures
\item \texttt{TypeError}: Invalid AST parsing
\end{itemize}
\end{itemize}

\subsubsection{Local Functions}

\paragraph{\texttt{\_find\_subclasses(directory: Path)}}
\begin{itemize}
\item \textbf{Transition}: Discovers class hierarchy relationships
\item \textbf{Output}: Updates \texttt{valid\_classes} state
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{find\_valid\_method\_calls(...)}}
\begin{itemize}
\item \textbf{Transition}: Identifies call sites needing modification
\item \textbf{Output}: Returns list of valid call tuples
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{check\_for\_initializations(...)}}
\begin{itemize}
\item \textbf{Transition}: Verifies variable initialization sources
\item \textbf{Output}: Returns initialization types list
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{check\_for\_annotations(...)}}
\begin{itemize}
\item \textbf{Transition}: Extracts type hints from annotations
\item \textbf{Output}: Returns annotation node or None
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{leave\_FunctionDef(...)}}
\begin{itemize}
\item \textbf{Transition}:
\begin{itemize}
\item Adds \texttt{@staticmethod} decorator
\item Removes \texttt{self} parameter
\end{itemize}
\item \textbf{Output}: Modified function node
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{CallTransformer}}
\begin{itemize}
\item \textbf{Transition}: Updates instance calls to static calls
\item \textbf{Output}: Modified call nodes
\item \textbf{Exception}: Raises \texttt{TypeError} for position errors
\end{itemize}

\newpage  


\section{MIS of Long Element Chain Refactorer} \label{mis:lec}

\texttt{LongElementChainRefactorer}

\subsection{Module}

LongElementChainRefactorer is a module that refactors long element chains, specifically focusing on flattening nested dictionaries to improve readability, maintainability, and energy efficiency. The module uses a recursive flattening strategy while caching previously seen patterns for optimization.

\subsection{Uses}

\begin{itemize}
\item Uses \texttt{Smell} interface for data access
\item Inherits from \texttt{BaseRefactorer}
\end{itemize}

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}


\begin{center}
\begin{tabularx}{\linewidth}{|l|>{\raggedright\arraybackslash}X|l|l|}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
\texttt{LongElementChainRefactorer} & \texttt{output\_dir: Path} & \texttt{self} & None \\
\hline
\texttt{refactor} & \texttt{file\_path: Path, pylint\_smell: Smell, initial\_emissions: $\mathbb{R}$} & None & \texttt{TypeError}, \texttt{IOError} \\
\hline
\end{tabularx}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

\begin{itemize}
\item \textbf{\_reference\_map}: Maps element chain references to their line numbers and corresponding values.
\item \textbf{dict\_name}: Names of target dictionaries to refactor.
\item \textbf{access\_patterns}: Collection of detected dictionary access patterns.
\item \textbf{dict\_assignment}: Flattened version of the original nested dictionary.
\end{itemize}

\subsubsection{Environment Variables}
None

\subsubsection{Assumptions}

\begin{itemize}
\item Input files are valid Python scripts.
\item Smells identified by \textbf{pylint\_smell} include valid line numbers.
\item Refactored code must pass the provided test suite.
\end{itemize}

\subsubsection{Access Routine Semantics}

\paragraph{\texttt{LongElementChainRefactorer(output\_dir: Path)}}
\begin{itemize}
\item \textbf{Transition}: Initializes the refactorer with the specified output directory and sets up internal caching structures.
\item \textbf{Output}: \texttt{self}.
\item \textbf{Exception}: None.
\end{itemize}

\paragraph{\texttt{refactor(file\_path: Path, pylint\_smell: Smell, initial\_emissions: R R)}}
\begin{itemize}
\item \textbf{Transition}:
\begin{itemize}
\item Reads the file at \texttt{file\_path} and parses its AST.
\item Identifies dictionary names using \texttt{\_find\_dict\_names} and \texttt{\_extract\_dict\_name}.
\item Detects nested access patterns via \texttt{\_find\_access\_pattern\_in\_file} and \\ \texttt{extract\_full\_dict\_access}.
\item Calculates nesting depth with \texttt{\_count\_nested\_subscripts}.
\item Locates dictionary assignments using \texttt{find\_dict\_assignment\_in\_file} and converts AST nodes with \texttt{extract\_dict\_literal}.
\item Flattens the dictionary using \texttt{flatten\_dict}.
\item Generates new access keys via \texttt{generate\_flattened\_access}.
\item Applies code modifications using \texttt{\_collect\_line\_modifications} and \texttt{\_apply\_modifications}.
\item Updates the original dictionary assignment with \texttt{\_update\_dict\_assignment}.
\item Writes the refactored code to a temporary file.
\end{itemize}
\item \textbf{Output}: None. Refactored file is saved if improvements are validated.
\item \textbf{Exception}: Raises \texttt{IOError} if input file cannot be read. Raises \texttt{TypeError} if source file cannot be parsed into an AST.
\end{itemize}

\subsubsection{Local Functions}

\paragraph{\texttt{\_find\_dict\_names(tree: ast.AST, line\_number: int)}}
\begin{itemize}
\item \textbf{Transition}: Identifies dictionary names in the AST at the specified line number.
\item \textbf{Output}: None (updates \texttt{dict\_name} state variable).
\item \textbf{Exception}: None.
\end{itemize}

\paragraph{\texttt{\_extract\_dict\_name(node: ast.AST)}}
\begin{itemize}
\item \textbf{Transition}: Extracts the dictionary name from attribute/subscript nodes in the AST.
\item \textbf{Output}: Returns the extracted name as a string or \texttt{None}.
\item \textbf{Exception}: None.
\end{itemize}

\paragraph{\texttt{\_find\_access\_pattern\_in\_file(tree: ast.AST, path: Path)}}
\begin{itemize}
\item \textbf{Transition}: Detects all dictionary access patterns in a file's AST.
\item \textbf{Output}: None (populates \texttt{access\_patterns} state variable).
\item \textbf{Exception}: None.
\end{itemize}

\paragraph{\texttt{extract\_full\_dict\_access(node: ast.Subscript)}}
\begin{itemize}
\item \textbf{Transition}: Extracts the full access chain (e.g., \texttt{dict['key1']['key2']}) from a Subscript node.
\item \textbf{Output}: Returns tuple containing dictionary name, access chain, line number, and column offset.
\item \textbf{Exception}: None.
\end{itemize}

\paragraph{\texttt{\_count\_nested\_subscripts(node: ast.Subscript)}}
\begin{itemize}
\item \textbf{Transition}: Counts the nesting level of subscript accesses.
\item \textbf{Output}: Returns nesting level as an integer.
\item \textbf{Exception}: None.
\end{itemize}

\paragraph{\texttt{find\_dict\_assignment\_in\_file(tree: ast.AST)}}
\begin{itemize}
\item \textbf{Transition}: Locates dictionary assignments in the AST and extracts their values.
\item \textbf{Output}: None (updates \texttt{dict\_assignment} state variable).
\item \textbf{Exception}: None.
\end{itemize}

\paragraph{\texttt{extract\_dict\_literal(node: ast.AST)}}
\begin{itemize}
\item \textbf{Transition}: Converts an AST dictionary node to a Python dictionary.
\item \textbf{Output}: Returns the converted dictionary.
\item \textbf{Exception}: None.
\end{itemize}

\paragraph{\texttt{flatten\_dict(d: dict[str, Any], depth: int, parent\_key: str)}}
\begin{itemize}
\item \textbf{Transition}: Recursively flattens a nested dictionary by combining keys with underscores.
\item \textbf{Output}: Returns the flattened dictionary.
\item \textbf{Exception}: None.
\end{itemize}

\paragraph{\texttt{generate\_flattened\_access(access\_chain: list[str])}}
\begin{itemize}
\item \textbf{Transition}: Generates a flattened key string from an access chain.
\item \textbf{Output}: Returns the refactored access string.
\item \textbf{Exception}: None.
\end{itemize}

\paragraph{\texttt{\_collect\_line\_modifications(file\_path: Path)}}
\begin{itemize}
\item \textbf{Transition}: Collects required code modifications for detected access patterns.
\item \textbf{Output}: Returns dictionary mapping line numbers to modifications.
\item \textbf{Exception}: None.
\end{itemize}

\paragraph{\texttt{\_apply\_modifications(lines: list[str], modifications: dict[int, list[tuple[int, str, str]]})}
\begin{itemize}
\item \textbf{Transition}: Applies collected modifications to source code lines.
\item \textbf{Output}: Returns list of modified code lines.
\item \textbf{Exception}: None.
\end{itemize}

\paragraph{\texttt{\_update\_dict\_assignment(refactored\_lines: list[str])}}
\begin{itemize}
\item \textbf{Transition}: Updates the original nested dictionary assignment with the flattened version.
\item \textbf{Output}: Returns modified code lines with updated dictionary.
\item \textbf{Exception}: None.
\end{itemize}

\section{MIS of Measurements Module} \label{mis:measure}

\texttt{Measurements}

\subsection{Module}

The MeasurementsModule is a module designed to measure and track the carbon emissions generated by executing scripts. By leveraging the CodeCarbon library, it allows developers to assess the environmental impact of their code execution. The module runs a specified Python file, tracks the associated carbon emissions during the execution, and logs the results for further analysis. It provides functionality for measuring, logging, and extracting emissions data in a structured manner to help improve energy efficiency in software development.


\subsection{Uses}

\begin{itemize}
\item Uses \texttt{CodeCarbon} library for track energy consumption
\item Uses \texttt{TemporaryDirectory} to store temporary files
\item Inherits from \texttt{BaseEnergyMeter}
\end{itemize}

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabularx}{\linewidth}{|l|>{\raggedright\arraybackslash}X|l|l|}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
\texttt{Measurements} & \texttt{output\_dir: Path} & \texttt{self} & None \\
\hline
\texttt{measure\_energy} & \texttt{None} & None & CalledProcessError and FileReading exceptions \\
\hline
\end{tabularx}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

\begin{itemize}
\item \textbf{emissions\_data}: Stores the emissions data extracted from the CSV file generated by CodeCarbon. It is populated after the energy measurement process completes successfully. The value is either a dictionary containing the last row of emissions data or \texttt{None} if no data was extracted due to an error.
\item \textbf{emissions}: Raw emissions object from CodeCarbon tracker
\end{itemize}

\subsubsection{Environment Variables}
None

\subsubsection{Assumptions}

\begin{itemize}
\item The file at \texttt{file\_path} is a valid Python script.
\item The CodeCarbon tool is properly installed and configured.
\item The \texttt{EmissionsTracker} can successfully execute the Python script specified by \texttt{file\_path}.
\item The emissions data is captured in a CSV format and can be extracted correctly.
\item The temporary directories are correctly set up and accessible during execution.
\end{itemize}

\subsubsection{Access Routine Semantics}

\paragraph{\texttt{Measurements(output\_dir: Path)}}
\begin{itemize}
\item \textbf{Transition}: Initializes the energy meter with empty emissions data
\item \textbf{Output}: \texttt{self}
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{measure\_energy()}}
\begin{itemize}
\item \textbf{Transition}:
\begin{itemize}
\item Logs the start of the energy measurement process
\item Creates isolated temporary directory using \texttt{TemporaryDirectory}
\item Configures system temp directories through environment variables
\item Initializes CodeCarbon \texttt{EmissionsTracker} in process mode
\item Runs the script specified by file path and captures the output
\item Stops tracker and captures raw emissions data
\item Validates emissions CSV creation
\item Parses results using \texttt{extract\_emissions\_csv}
\end{itemize}
\item \textbf{Output}:
\begin{itemize}
\item Updates \texttt{emissions} with tracker results
\item Populates \texttt{emissions\_data} with parsed metrics
\end{itemize}
\item \textbf{Exception}:
\begin{itemize}
\item \texttt{CalledProcessError}: If script execution fails
\item \texttt{FileNotFoundError}: If emissions CSV is missing
\end{itemize}
\end{itemize}

\subsubsection{Local Functions}

\paragraph{\texttt{extract\_emissions\_csv(csv\_file\_path: Path)}}
\begin{itemize}
\item \textbf{Transition}:
\begin{itemize}
\item Attempts to read CSV file using pandas
\item Extracts last measurement record
\item Converts DataFrame row to dictionary
\end{itemize}
\item \textbf{Output}: Returns dictionary of metrics or \texttt{None} on error
\item \textbf{Exception}: Logs pandas read errors but does not propagate them
\end{itemize}
  
  
\newpage
\section{MIS of Pylint Analyzer} \label{mis:PylintAnalyzer}

\texttt{PylintAnalyzer}

\subsection{Module}

The \texttt{PylintAnalyzer} module performs static code analysis on Python files using Pylint, with additional custom checks for detecting specific code smells. It outputs detected smells in a structured format for further processing.

\subsection{Uses}
\begin{itemize}
\item Uses Python's \texttt{pylint} library for code analysis
\item Uses \texttt{ast} module for parsing and analyzing abstract syntax trees
\item Uses \texttt{astor} library for converting AST nodes back to source code
\item Integrates with custom checkers, including \texttt{StringConcatInLoopChecker}
\item Accesses configuration settings from \texttt{analyzers\_config}
\end{itemize}

\subsection{Syntax}
\noindent
\textbf{Exported Constants}: None

\noindent
\textbf{Exported Access Programs}:\\
{\footnotesize
\begin{tabularx}{\linewidth}{|
    l|
    >{\raggedright\arraybackslash}X|
    l|
    l|}
  \hline
  \textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\\hline
  \texttt{PylintAnalyzer} & \texttt{file\_path: Path, source\_code: Module} & \texttt{self} & None \\
  \hline
  \texttt{build\_pylint\_options} & None & \texttt{list[str]} & None \\
  \hline
  \texttt{analyze} & None & None & \texttt{JSONDecodeError}, \texttt{Exception} \\
  \hline
  \texttt{configure\_smells} & None & None & None \\
  \hline
  \texttt{filter\_for\_one\_code\_smell} & \texttt{pylint\_results: list[Smell], code: str} & \texttt{list[Smell]} & None \\
  \hline
\end{tabularx}
}

\subsection{Semantics}

\subsubsection{State Variables}
\begin{itemize}
\item \texttt{file\_path: Path}: The path to the Python file being analyzed
\item \texttt{source\_code: Module}: The parsed abstract syntax tree of the source file
\item \texttt{smells\_data: list[dict]}: List of detected code smells in dictionary format
\end{itemize}

\subsubsection{Environment Variables}
None

\subsubsection{Assumptions}
\begin{itemize}
\item The input file is valid Python code and can be parsed into an AST
\item Configuration settings (extra Pylint options, custom smell definitions) are valid
\end{itemize}

\subsubsection{Access Routine Semantics}

\paragraph{\texttt{PylintAnalyzer(file\_path: Path, source\_code: Module)}}
\begin{itemize}
\item \textbf{Transition}: Initializes analyzer with file path and AST
\item \textbf{Output}: \texttt{self}
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{build\_pylint\_options()}}
\begin{itemize}
\item \textbf{Transition}: Constructs Pylint options list from config
\item \textbf{Output}: List of option strings
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{analyze()}}
\begin{itemize}
\item \textbf{Transition}:
\begin{itemize}
\item Executes Pylint analysis with custom checks using the local detect functions
\item Populates \texttt{smells\_data} with results and uses \texttt{parse\_line}
\end{itemize}
\item \textbf{Output}: None
\item \textbf{Exception}:
\begin{itemize}
\item \texttt{JSONDecodeError} for invalid Pylint output
\item \texttt{Exception} for general runtime errors
\end{itemize}
\end{itemize}

\paragraph{\texttt{configure\_smells()}}
\begin{itemize}
\item \textbf{Transition}: Filters \texttt{smells\_data} to configured smells
\item \textbf{Output}: None
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{filter\_for\_one\_code\_smell(pylint\_results: list[Smell], code: str)}}
\begin{itemize}
\item \textbf{Transition}: Filters results by smell type code
\item \textbf{Output}: Filtered list of smells
\item \textbf{Exception}: None
\end{itemize}

\subsubsection{Local Functions}

\paragraph{\texttt{detect\_long\_message\_chain(threshold?: int)}}
\begin{itemize}
\item \textbf{Transition}: Identifies method chains exceeding length threshold
\item \textbf{Output}: List of long chain smells
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{detect\_long\_lambda\_expression(threshold\_length?: int, threshold\_count?: int)}}
\begin{itemize}
\item \textbf{Transition}: Detects oversized lambda expressions
\item \textbf{Output}: List of lambda smells
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{detect\_long\_element\_chain(threshold?: int)}}
\begin{itemize}
\item \textbf{Transition}: Finds long dictionary access chains
\item \textbf{Output}: List of element chain smells
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{detect\_repeated\_calls(threshold?: int)}}
\begin{itemize}
\item \textbf{Transition}: Identifies excessive repeated calls
\item \textbf{Output}: List of repetition smells
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{parse\_line(file\_path: Path, line: int)}}
\begin{itemize}
\item \textbf{Transition}: Extracts AST node from specific line
\item \textbf{Output}: Parsed AST node
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{get\_lambda\_code(lambda\_node: Lambda)}}
\begin{itemize}
\item \textbf{Transition}: Converts lambda node to source code
\item \textbf{Output}: String representation of lambda
\item \textbf{Exception}: None
\end{itemize}

\newpage
\section{MIS of Use A Generator Refactorer} \label{mis:UseGen}

\texttt{UseAGeneratorRefactorer}

\subsection{Module}

The \texttt{UseAGeneratorRefactorer} module identifies and refactors 
unnecessary list comprehensions in Python code by converting them to generator expressions. This refactoring improves energy efficiency while maintaining the original functionality.

\subsection{Uses}
\begin{itemize}
\item Uses \texttt{Smell} interface for data access
\item Inherits from \texttt{BaseRefactorer}
\item Uses Python's \texttt{ast} module for parsing and manipulating abstract syntax trees
\end{itemize}

\subsection{Syntax}
\noindent
\textbf{Exported Constants}: None


\noindent
\textbf{Exported Access Programs}:\\
\begin{tabularx}{\linewidth}{|
    l|
    >{\raggedright\arraybackslash}X|
    l|
    l|}
  \hline
  \textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\\hline
  \texttt{UseAGeneratorRefactorer} & \texttt{output\_dir: Path} & \texttt{self} & None \\
  \hline
  \texttt{refactor} & \texttt{file\_path: Path, pylint\_smell: Smell, initial\_emissions: $\mathbb{R}$} & None & \texttt{IOError}, \texttt{TypeError} \\
  \hline
\end{tabularx}

\subsection{Semantics}

\subsubsection{State Variables}
\begin{itemize}
\item \texttt{temp\_dir: Path}: Directory path for storing refactored files
\item \texttt{output\_dir: Path}: Directory path for saving final refactored code
\end{itemize}

\subsubsection{Environment Variables}
None

\subsubsection{Assumptions}
\begin{itemize}
\item The input file contains valid Python syntax
\item \texttt{pylint\_smell} provides valid line/column locations
\end{itemize}

\subsubsection{Access Routine Semantics}

\paragraph{\texttt{UseAGeneratorRefactorer(output\_dir: Path)}}
\begin{itemize}
\item \textbf{Transition}: Initializes temporary directory within output directory
\item \textbf{Output}: \texttt{self}
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{refactor(file\_path: Path, pylint\_smell: Smell, initial\_emissions: 
R
R)}}
\begin{itemize}
\item \textbf{Transition}:
\begin{itemize}
\item Reads source code using \texttt{ListCompInAnyAllTransformer} metadata
\item Applies AST transformation via \texttt{\_replace\_node} for node substitution
\item Uses \texttt{leave\_Call} in transformer to identify replacement targets
\item Validates and writes modified code using generator expressions
\end{itemize}
\item \textbf{Output}: None
\item \textbf{Exception}:
\begin{itemize}
\item \texttt{IOError}: File read/write failures
\item \texttt{TypeError}: CST parsing errors
\end{itemize}
\end{itemize}

\subsubsection{Local Functions}

\paragraph{\texttt{\_replace\_node(tree: Module, old\_node: ListComp, new\_node: GeneratorExp)}}
\begin{itemize}
\item \textbf{Transition}: Replaces list comprehension node with generator expression
\item \textbf{Output}: Modified AST
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{ListCompInAnyAllTransformer}}
\begin{itemize}
\item \textbf{Transition}: Custom CST transformer that identifies and converts list comprehensions in any()/all() calls
\item \textbf{Output}: Modified syntax tree
\item \textbf{Exception}: None
\end{itemize}

\newpage

\section{MIS of Cache Repeated Calls Refactorer} \label{mis:CacheCalls}

\texttt{CacheRepeatedCallsRefactorer}

\subsection{Module}
The \texttt{CacheRepeatedCallsRefactorer} identifies and caches repeated function calls using temporary variables to improve performance and energy efficiency while preserving functionality.

\subsection{Uses}
\begin{itemize}
\item Uses \texttt{Smell} interface for data access
\item Inherits from \texttt{BaseRefactorer}
\item Uses Python's \texttt{ast} module for AST manipulation
\end{itemize}

\subsection{Syntax}
\noindent
\textbf{Exported Constants}: None

\noindent
\textbf{Exported Access Programs}:\\
\begin{tabularx}{\linewidth}{|l|>{\raggedright\arraybackslash}X|l|l|}
  \hline
  \textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\\hline
  \texttt{CacheRepeatedCallsRefactorer} & \texttt{output\_dir: Path} & \texttt{self} & None \\
  \hline
  \texttt{refactor} & \texttt{file\_path: Path, pylint\_smell: Smell, initial\_emissions: $\mathbb{R}$} & None & \texttt{IOError}, \texttt{TypeError} \\
  \hline
\end{tabularx}

\subsection{Semantics}

\subsubsection{State Variables}
\begin{itemize}
  \item \texttt{cached\_var\_name: str}: Name of the temporary variable used for caching.
  \item \texttt{target\_line: int}: Line number where refactoring is applied.
\end{itemize}

\subsubsection{Environment Variables}
None

\subsubsection{Assumptions}
\begin{itemize}
\item Input files contain valid Python syntax
\item Smell detection provides valid call patterns
\item Repeated calls have no side effects
\end{itemize}

\subsubsection{Access Routine Semantics}

\paragraph{\texttt{CacheRepeatedCallsRefactorer(output\_dir: Path)}}
\begin{itemize}
\item \textbf{Transition}: Initializes temp directory
\item \textbf{Output}: \texttt{self}
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{refactor(file\_path: Path, smell: CRCSmell, ...)}}
\begin{itemize}
\item \textbf{Transition}:
\begin{itemize}
\item Generates cache name via \texttt{extract\_function\_name}
\item Locates insertion point with \texttt{\_find\_insert\_line}
\item Determines indentation via \texttt{\_get\_indentation}
\item Modifies calls using \texttt{\_replace\_call\_in\_line}
\item Validates scope with \texttt{\_find\_valid\_parent}
\end{itemize}
\item \textbf{Output}: None
\item \textbf{Exception}:
\begin{itemize}
\item \texttt{IOError}: File access failures
\item \texttt{TypeError}: Invalid AST structure
\end{itemize}
\end{itemize}

\subsubsection{Local Functions}

\paragraph{\texttt{extract\_function\_name(call\_string: str)}}
\begin{itemize}
\item \textbf{Transition}: Extracts base name from call pattern
\item \textbf{Output}: Normalized function name string
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{\_get\_indentation(lines: list[str], line\_number: int)}}
\begin{itemize}
\item \textbf{Transition}: Calculates whitespace for code insertion
\item \textbf{Output}: Indentation string
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{\_replace\_call\_in\_line(line: str, call\_string: str, cached\_var\_name: str)}}
\begin{itemize}
\item \textbf{Transition}: Replaces function calls with cache variable
\item \textbf{Output}: Modified source line
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{\_find\_valid\_parent(tree: ast.Module)}}
\begin{itemize}
\item \textbf{Transition}: Locates common parent for all call instances
\item \textbf{Output}: Parent AST node or None
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{\_find\_insert\_line(parent\_node: ast.AST)}}
\begin{itemize}
\item \textbf{Transition}: Determines optimal insertion point
\item \textbf{Output}: Line number for cache assignment
\item \textbf{Exception}: None
\end{itemize}

\paragraph{\texttt{\_line\_in\_node\_body(node: ast.AST, line: int)}}
\begin{itemize}
\item \textbf{Transition}: Verifies line belongs to node body
\item \textbf{Output}: Boolean existence check
\item \textbf{Exception}: None
\end{itemize}

\newpage

\section{MIS of Plugin Initiator}

\subsection{Module}
\texttt{Plugin Initiator} is a module that initializes the VS Code plugin and registers commands for VS Code Plugin.

\subsection{Uses}
\begin{itemize}
    \item \texttt{Smell Detector} to register the command for detecting code smells.
    \item \texttt{Smell Refactorer} to register the command for refactoring user's selected code smell.
\end{itemize}

\subsection{Syntax}

\textbf{Exported Constants:} None\\
\noindent \textbf{Exported Access Programs:}
None


\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
None


\subsubsection{Assumptions}
\begin{itemize}
\item The plugin is correctly loaded in VS Code.
\item Source Code Optimizer executable is reachable and operational.
\end{itemize}

\subsubsection{Access Routine Semantics}
\texttt{activate()}
\begin{itemize}
\item \textbf{Transition}: Activates the plugin and registers commands.
\item \textbf{Output}: None.
\item \textbf{Exception}: None.
\end{itemize}

\subsubsection{Local Functions}
None

\section{MIS of Backend Communicator}

\subsection{Module}
\texttt{BackendCommunicator} handles all communication between the plugin and the backend service. It sends requests for analysis or refactoring and receives results.

\subsection{Uses}
Source Code Optimizer executable for energy measurement, smell detection and refactoring of applications.

\subsection{Syntax}

\textbf{Exported Constants:} None

\noindent \textbf{Exported Access Programs:}\\
\begin{tabularx}{\linewidth}{|l|>{\raggedright\arraybackslash}X|l|l|}
  \hline
  \textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
  \hline
  \texttt{sendRequest} & \texttt{requestType: string, data: any} & Promise & Communication Error \\
  \hline
\end{tabularx}


\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
None

\subsubsection{Assumptions}
\begin{itemize}
\item Source Code Optimizer executable is reachable and operational.
\item Python file with no syntax errors is present in the VS Code editor.
\end{itemize}

\subsubsection{Access Routine Semantics}
\texttt{sendRequest(requestType: str, data: Any)}
\begin{itemize}
\item \textbf{Transition}: Sends the provided request to Source Code Optimizer and receives a response.
\item \textbf{Output}: A promise that resolves with Source Code Optimizer's response.
\item \textbf{Exception}: Logs any errors encountered during communication.
\end{itemize}

\subsubsection{Local Functions}
None

\section{MIS of Smell Detector}

\subsection{Module}
\texttt{Smell Detector} analyzes the active file for code smells and interacts with Source Code Optimizer for detection.

\subsection{Uses}
\begin{itemize}
\item \texttt{Backend Communicator} for communicating with Source Code Optimizer for smell detection.
\item \texttt{File Highlighter} for highlighting detected smells in the editor.
\end{itemize}

\subsection{Syntax}

\textbf{Exported Constants:} None

\textbf{Exported Access Programs:}\\
\begin{tabularx}{\linewidth}{|l|>{\raggedright\arraybackslash}X|l|l|}
  \hline
  \textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
  \hline
  \texttt{detect} & None & None & Active file not found \\
  \hline
\end{tabularx}

\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
None


\subsubsection{Assumptions}
\begin{itemize}
\item There is an active Python file with no syntax error in the editor.
\item Source Code Optimizer correctly identifies smells.
\end{itemize}

\subsubsection{Access Routine Semantics}
\texttt{detect()}
\begin{itemize}
\item \textbf{Transition}: Reads the active file, sends it to Source Code Optimizer for analysis, and highlights detected smells in the editor.
\item \textbf{Output}: None.
\item \textbf{Exception}: Throws an error if no active file is found.
\end{itemize}

\subsubsection{Local Functions}
None

\section{MIS of Smell Refactorer}

\subsection{Module}
\texttt{Smell Refactorer} applies a refactoring to a detected smell.

\subsection{Uses}
\begin{itemize}
\item \texttt{Backend Communicator} for sending the smell data to Source Code Optimizer for refactoring.
\item \texttt{Refactor Manager} for managing refactoring workflows.
\end{itemize}

\subsection{Syntax}

\textbf{Exported Constants:} None

\textbf{Exported Access Programs:}\\
\begin{tabularx}{\linewidth}{|l|>{\raggedright\arraybackslash}X|l|l|}
  \hline
  \textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exception}\\
  \hline
  \texttt{refactor} & {smell: Smell} & None & Invalid input \\
  \hline
\end{tabularx}

\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
None


\subsubsection{Assumptions}
\begin{itemize}
\item The smell data is valid and correctly identifies a refactorable issue.
\end{itemize}

\subsubsection{Access Routine Semantics}
\texttt{refactor(smell: Smell)}
\begin{itemize}
\item \textbf{Transition}: Sends the smell data to the backend for refactoring and applies the changes in the editor.
\item \textbf{Output}: None.
\item \textbf{Exception}: Logs errors for invalid inputs or failed refactoring.
\end{itemize}

\subsubsection{Local Functions}
None

\section{MIS of File Highlighter}

\subsection{Module}
\texttt{File Highlighter} is a module that manages highlighting of code regions in the VS Code editor.

\subsection{Uses}
None

\subsection{Syntax}

\textbf{Exported Constants:} None

\noindent \textbf{Exported Access Programs:}\\
\begin{tabularx}{\linewidth}{|l|>{\raggedright\arraybackslash}X|l|l|}
  \hline
  \textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exception} \\
  \hline
  \texttt{highlight} & \texttt{range: range[]} & None & None \\ \hline
  \texttt{clear} & \texttt{None} & None & None \\
  \hline
\end{tabularx}

\subsection{Semantics}

\subsubsection{State Variables}
\begin{itemize}
\item \texttt{highlightedRanges}: Stores the currently highlighted regions in the editor.
\end{itemize}

\subsubsection{Environment Variables}
None


\subsubsection{Assumptions}
\begin{itemize}
\item The VS Code editor is active and accessible.
\item Python file with no syntax errors is currently open in the editor.
\end{itemize}

\subsubsection{Access Routine Semantics}
\texttt{highlight(ranges: Range[])}
\begin{itemize}
\item \textbf{Transition}: Adds highlights to the specified ranges in the editor.
\item \textbf{Output}: None.
\item \textbf{Exception}: None.
\end{itemize}

\texttt{clear()}
\begin{itemize}
\item \textbf{Transition}: Removes all highlights from the editor.
\item \textbf{Output}: None.
\item \textbf{Exception}: None.
\end{itemize}

\subsubsection{Local Functions}
None

\section{MIS of Hover Manager}

\subsection{Module}
\texttt{Hover Manager} manages hover effects to display contextual information.

\subsection{Uses}
\begin{itemize}
\item \texttt{File Highlighter} for providing contextual information about highlighted smells.
\end{itemize}

\subsection{Syntax}

\textbf{Exported Constants:} None

\textbf{Exported Access Programs:}\\
\begin{tabularx}{\linewidth}{|l|>{\raggedright\arraybackslash}X|l|l|}
  \hline
  \textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exception} \\
  \hline
  \texttt{showHover} & \texttt{position: Position} & None & None \\ \hline
  \texttt{clearHover} & \texttt{None} & None & None \\
  \hline
\end{tabularx}

\subsection{Semantics}

\subsubsection{State Variables}
\begin{itemize}
\item \texttt{currentHover}: Stores the currently displayed hover information.
\end{itemize}

\subsubsection{Environment Variables}
None


\subsubsection{Assumptions}
None

\subsubsection{Access Routine Semantics}
\texttt{showHover(position: Position)}
\begin{itemize}
\item \textbf{Transition}: Displays hover information at the specified position.
\item \textbf{Output}: None.
\item \textbf{Exception}: None.
\end{itemize}

\texttt{clearHover()}
\begin{itemize}
\item \textbf{Transition}: Clears any active hover information.
\item \textbf{Output}: None.
\item \textbf{Exception}: None.
\end{itemize}

\subsubsection{Local Functions}
None

\section{MIS of Refactor Manager}

\subsection{Module}
\texttt{Refactor Manager} manages the process of applying refactorings to detected smells.

\subsection{Uses}
None

\subsection{Syntax}

\textbf{Exported Constants:} None

\textbf{Exported Access Programs:}\\
\begin{tabularx}{\linewidth}{|l|>{\raggedright\arraybackslash}X|l|l|}
  \toprule Name & In & Out & Exceptions \\
  \midrule
  \texttt{applyRefactor} & \texttt{refactor: Refactor} & None & Validation error \\ \hline
  \texttt{previewRefactor} & \texttt{refactor: Refactor} & None & None \\ \hline
  \texttt{undoRefactor} & None & None & None \\
  \bottomrule
\end{tabularx}

\subsection{Semantics}

\subsubsection{State Variables}
\begin{itemize}
\item \texttt{appliedRefactors}: Stores a history of applied refactors.
\end{itemize}

\subsubsection{Environment Variables}
None


\subsubsection{Assumptions}
\begin{itemize}
\item The refactoring data is valid and corresponds to detected smells.
\end{itemize}

\subsubsection{Access Routine Semantics}
\texttt{applyRefactor(refactor: Refactor)}
\begin{itemize}
\item \textbf{Transition}: Applies the provided refactor to the active editor.
\item \textbf{Output}: None.
\item \textbf{Exception}: Logs validation errors if the refactor cannot be applied.
\end{itemize}

\texttt{previewRefactor(refactor: Refactor)}
\begin{itemize}
\item \textbf{Transition}: Displays a preview of the refactor in the editor.
\item \textbf{Output}: None.
\item \textbf{Exception}: None.
\end{itemize}

\texttt{undoRefactor()}
\begin{itemize}
\item \textbf{Transition}: Reverts the most recently applied refactor.
\item \textbf{Output}: None.
\item \textbf{Exception}: None.
\end{itemize}

\subsubsection{Local Functions}
None

% \bibliographystyle {plainnat}
% \bibliography {../../../refs/References}

\newpage

\section{Appendix --- Reflection}

\wss{Not required for CAS 741 projects}

The information in this section will be used to evaluate the team members on the
graduate attribute of Problem Analysis and Design.

\input{../../Reflection.tex}

\subsubsection*{Group Reflection}

\begin{enumerate}
  \item \textit{Which of your design decisions stemmed from speaking to your client(s)
  or a proxy (e.g. your peers, stakeholders, potential users)? For those that
  were not, why, and where did they come from?}

  The decision to modularize the refactorers into specific "smell-focused" 
  components was largely inspired by a conversation with our supervisor, 
  who is also our primary stakeholder. During one of our discussions, our 
  supervisor suggested that the problem at hand had the potential to 
  evolve into a graduate-level reinforcement learning project. This 
  idea of managing multiple refactoring strategies and selecting the 
  best one based on certain conditions led to the insight that 
  organizing the refactorers by the specific types of code smells 
  they address would make the system more extensible. By focusing 
  each component on a particular code smell, we could later build 
  upon the design and possibly incorporate machine learning or 
  reinforcement learning strategies to optimize refactorer selection. 
  This modular approach would allow for easier integration of additional 
  strategies in the future, making the tool scalable as the project evolves.


  Another important design decision influenced by our supervisor was the 
  idea to validate the refactored code using a test suite. Our supervisor 
  emphasized that in a real-world application, validating the integrity 
  of the refactored code with a comprehensive test suite was a crucial step. 

  Both of these design decisions were informed by valuable input from our 
  supervisor, ensuring that the project stayed grounded in real-world 
  applicability and allowed for future enhancements and improvements.


  \item \textit{While creating the design doc, what parts of your other documents (e.g.
  requirements, hazard analysis, etc), it any, needed to be changed, and why?}
  
  While creating the design document, several components of the project were revised to improve clarity and focus. Specifically, the list of code smells targeted by the refactoring library was refined by adding new smells that align more closely with our sustainability goals and removing others deemed less impactful. This required updates to the requirements document to ensure it accurately reflected the new scope of supported refactorings. Additionally, the decision was made to remove the metric reporting functionality due to its complexity and limited time, which led to corresponding modifications in both the requirements document and the VnV plan, where this feature had previously been considered for validation. Moreover, the reinforcement learning model, initially intended to optimise refactoring decisions, was excluded from the project due to time constraints and implementation challenges. This necessitated updates to the hazard analysis document to remove risks associated with this component and to better align the analysis with the reduced project scope. These changes ensure consistency and maintain a realistic and achievable project timeline. 

  \item \textit {What are the limitations of your solution?  Put another way, given unlimited resources, what could you do to make the project better? (LO\_ProbSolutions)}

  The energy measurement library we selected, Codecarbon, proved to be less reliable 
  than anticipated, which affects the accuracy of some of our results. Ideally, 
  we would replace it with a more dependable resource. However, due to time 
  constraints and the inherent complexity of measuring CO2 emissions from code, 
  this isnâ€™t feasible within the scope of this project. For now, we are assuming 
  Codecarbonâ€™s reliability. In a real-world implementation, we would prioritize 
  using a more robust energy measurement system.

  \item \textit {Give a brief overview of other design solutions you considered.  What
  are the benefits and tradeoffs of those other designs compared with the chosen
  design?  From all the potential options, why did you select the documented design?
  (LO\_Explores)}

  We considered incorporating a machine learning aspect into the project, 
  specifically using reinforcement learning (RL) to manage the refactoring 
  process. The idea was to treat the selection and application of 
  refactoring strategies as a decision-making process, where an agent 
  could learn the best strategies over time based on rewards and outcomes.

  In this approach, the agent would represent the system that applies 
  different refactoring techniques to the code. The environment would 
  be the code itself, with various code smells and inefficiencies that 
  the agent needs to address. The actions the agent would take would 
  involve selecting and applying one of the predefined refactoring 
  strategies (like long lambda function or long parameter list). The reward 
  would be the resulting decrease in energy consumption (i.e., reduction 
  in CO2 emissions), measured after the code is refactored and executed. 
  The agent would receive a positive reward for actions that successfully 
  lead to more energy-efficient code and a negative reward for actions 
  that increase energy consumption. Over time, the agent would learn to 
  prioritize and apply the most effective refactoring techniques based 
  on the rewards it receives.


  While this machine learning solution seemed promising, there were a 
  few trade-offs to consider. First, implementing reinforcement 
  learning would significantly increase the complexity of the project. 
  It would require training data, fine-tuning the agent's learning parameters, 
  and ensuring that the agent's actions actually lead to measurable 
  improvements in CO2 efficiency. Additionally, RL would require 
  ongoing iteration to improve its performance, which could be time-consuming 
  and resource-intensive, especially given the limited time available 
  for the project.


  Another concern was that reinforcement learning, while powerful, 
  might not always be the most effective or efficient solution for 
  this kind of task. The selection of refactoring strategies is not 
  necessarily a highly complex decision-making process that requires 
  learning over time. Since we already have a set of predefined 
  strategies, a more direct, rule-based approach was more appropriate. 
  We could achieve the same results without the need for training the 
  agent or dealing with the unpredictability of machine learning models.


  Given these trade-offs, we opted to stick with the more straightforward 
  approach of selecting and applying refactoring strategies based on 
  predefined rules. This decision was driven by the need for a practical 
  and efficient solution within the given project constraints. While 
  reinforcement learning could be an interesting exploration for future 
  versions of the tool, the current design provides a reliable and 
  manageable way to achieve the desired results without adding 
  unnecessary complexity.


\end{enumerate}

\subsubsection*{Mya Hussain}

\begin{enumerate}
  \item \textit{What went well while writing this deliverable? }
  
  Writing the deliverable helped to clearly decompose the system into manageable modules.
  This ensured no functionality was missed in the implementation process and that all 
  components connected in a way that made sense. 

  \item \textit{What pain points did you experience during this deliverable, and how did you resolve them?}

  It was strange that we had already coded the project before completing this deliverable.
  It acted as more of a sanity check that our design decisions made sense rather than 
  an actual blueprint of what to do. This made this deliverable easier to write as 
  the code was already present but also made the work feel unnecessarily redundant i.e boring to do.
  It often felt like I was documenting things that were already clear or implemented. 
  This repetition made the process less engaging and, at times, a bit tedious. 
  To resolve this, I focused on framing the document as an opportunity to validate 
  and formalize our design decisions, which helped shift the mindset from simply 
  checking off tasks to reaffirming the thought process behind our choices.
    
\end{enumerate}

\subsubsection*{Sevhena Walker}

\begin{enumerate}
  \item \textit{What went well while writing this deliverable? }

  Our team already had a pretty solid idea of how we wanted to break up our system, as well as the key components that should be involved, even before we started working on the MG and MIS documents. We had already coded a decent portion of the system and, in doing so, had explored and tested various design approaches and options. This hands-on experience gave us a strong foundation and a practical understanding of what worked and what didnâ€™t, which significantly influenced our final design choices. For example, we had already determined that the refactorers would be structured as individual classes inheriting from a common base class, which simplified documenting shared functionality in the MIS.

  \item \textit{What pain points did you experience during this deliverable, and how did you resolve them?}
  
  One of the biggest pain points was turning our informal design ideas and code into well-defined, modular components with clear inputs, outputs, and semantics. We had to carefully review the existing code to make sure the documentation matched its behaviour while keeping things flexible for future changes. We also ran into some inconsistencies that required minor refactoring to clean up our interfaces. Another tricky part was finding the right balance between providing enough detail and keeping the documentation readable without going too deep into implementation. We tackled these problems by reviewing everything multiple times, getting feedback, and simplifying where we could to make things clearer.

\end{enumerate}

\subsection*{Nivetha Kuruparan}

\begin{enumerate}
  \item \textit{What went well while writing this deliverable? }
  Planning out the different modules early on was incredibly helpful for me. It allowed me to clearly identify how various parts of the system interact and what functionality could be combined or separated. This structured approach not only helped in designing the system but also made it easier to focus on what each module should accomplish, ensuring no major functionality was overlooked.

  \item \textit{What pain points did you experience during this deliverable, and how did you resolve them?}
    It was challenging for me to think through each module thoroughly and ensure that every input, output, and state variable was captured accurately. This required going through the implementation multiple times and considering edge cases that might not have been obvious at first. Breaking the process into smaller, more manageable tasks and carefully reviewing each module helped resolve this challenge.

    
\end{enumerate}

\subsection*{Ayushi Amin}

\begin{enumerate}
  \item \textit{What went well while writing this deliverable? }
  Honestly, once I got into it, things flowed pretty smoothly. Breaking everything down into 
  smaller sections helped a ton. It made the whole thing feel less intimidating. I also felt like 
  I had a good understanding of how the modules all connected, which made it easier to explain things.
  We all had our own parts to work on based on the modules we have and were going to create so it was easier to 
  work on something I was familiar with. Also, talking it through with my teammates about some of the trickier 
  parts really helped me feel more confident about what I was writing. We all did code reviews and helped eachother out on
  parts we didn't quite get or thought we got. Overall, it felt pretty satisfying to see it all come together.
  
  \item \textit{What pain points did you experience during this deliverable, and how did you resolve them?}
  I think the hardest part of this was visualizing extra dependencies and functions I would need to create to make my 
  module work. We had coded out a portion of it but it did not include everything. I had to make sure I was not missing 
  anything important. It felt like I was stuck in this loop of overthinking every little detail. To get past it, I took a 
  break and came back with a fresh perspective, which helped a bit. I also hit up one of my teammates to talk through the 
  parts I was struggling with. They gave me some ideas and helped me confirm I was on the right track since some of the 
  modules I did were similar to theirs so we were able to collaborate easily. After that, things did not feel as stressful, 
  and I was able to wrap it up.
  
\end{enumerate}

\subsection*{Tanveer Brar}

\begin{enumerate}
  \item \textit{What went well while writing this deliverable? }
  The best part about writing this deliverable was getting the chance to design the user interface before having implemented it. The Source Code Optimizer has already been designed
  and implemented as a result of the POC assignment in November. We had not implemented the VS Code Plugin for it yet, so getting the chance to actually think about its 
  design was very rewarding(especially since most academic projects I have done before either involved no design component or very minimal for a small program). Each modules has clear 
  responsibilities, which helped me anticipate all needed requirements for this plugin through a logical framework(POC implementation was a lot of trial and error).
  The other good thing were the built in labels for anticipated changes and modules, which helped me easily write down the traceability matrix.
  
  \item \textit{What pain points did you experience during this deliverable, and how did you resolve them?}
  One of the biggest challenges that I faced was identifying the correct module for each anticipated change in the traceability matrix. My team mate had worked on the anticipated
  changes, Some of these changes had overlapping responsibilities across modules, so I carefully reviewd the module responsibilities over again to be able to point out the modules for 
  each change. It needed a lot of cross referencing the module guide and anticipated changes to make sure nothing was missde. 
  Also, when determining module dependencies in the "Uses" section for each module's decomposition, I was not fully sure about which modules should depend on which for the VS Code Plugin.
  This is because there can be multiple possible ways, for example the Plugin Initializer or Smell Detector being able to directly call Source Code Optimizer. While resolving this, I realized that 
  while there is no one perfect mapping of dependencies, the goal should be to be as modular as possible and apply the seperation of concerns principle. This is why, for example, the Backend Communicator 
  is the only module in the design that communicates with Source Code Optimizer.
\end{enumerate}


\end{document}